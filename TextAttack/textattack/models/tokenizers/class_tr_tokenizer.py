"""
Classifier Tokenizer
---------------------------------------------------------------------

"""

import transformers


class ClassTrTokenizer:
    """Tokenizer for the classifier in translation attack.
    """

    def __init__(self, name):
        self.tokenization_prefix = ""

        self.tokenizer = transformers.AutoTokenizer.from_pretrained(name, use_fast=True)
        # self.tokenizer = transformers.AutoTokenizer.from_pretrained("moussaKam/barthez-sentiment-classification", use_fast=True)
        self.tokenizer.model_max_length = 512
        


    def __call__(self, text, *args, **kwargs):
        """
        Args:
            text (:obj:`str`, :obj:`List[str]`):
                    The sequence or batch of sequences to be encoded. Each sequence can be a string or a list of strings.
        """
        assert isinstance(text, str) or (
            isinstance(text, (list, tuple))
            and (len(text) == 0 or isinstance(text[0], str))
        ), "`text` must be a string or a list of strings."
        if isinstance(text, str):
            text = self.tokenization_prefix + text
        else:
            for i in range(len(text)):
                text[i] = self.tokenization_prefix + text[i]
        return self.tokenizer(text, *args, **kwargs)

    def decode(self, ids):
        """Converts IDs (typically generated by the model) back to a string."""
        return self.tokenizer.decode(ids,skip_special_tokens=True)
